# name: Replace with any name for your model
# description: Replace with any description for your model
# version: Replace with any version of your model
# gpus: Replace with the number of gpus to be used in
#       training your model
# cpus: Replace with the number of cpus to be used in
#       training your model
# learners: Replace with the number of learner nodes to be used
# memory: Replace with the amount of memory to be
#         dedicated to training your model
name: Pytorch DDL on torchvision dataset
description: Test of Pytorch c10d Data Parallelism on FfDL
version: "1.0"
gpus: 1
cpus: 16
learners: 2
memory: 16Gb

# Object stores that allow the system to retrieve training data.
# id: The data_store id
# type: The type of data_store
# training_data: container: Replace with the name of the bucket at which
#                           you stored the fashion MNIST dataset
# training_results: container: Replace with the name of the bucket where
#                              the resulting model should be saved to
# connection: type: The type of connection
# connection: auth_url: Replace with your Cloud Object Storage Endpoint url
#                       for IBM Cloud
# connection: user_name: Replace with the access_key_id found in the service
#                        credentials tab on IBM Cloud
# connection: password: Replace with the secret_access_key found in service
#                       credentials tab on IBM Cloud
data_stores:
  - id: test-datastore
    type: mount_cos
    training_data:
      container: trainingdata
    training_results:
      container: trainedmodel
    connection:
      # Update the object storage credentials below
      auth_url: http://s3.default.svc.cluster.local
      user_name: test
      password: test

# name:    The name of the Deep Learning framework that will be used
# version: The version of the framework to be used
# command: The command to initiate training
framework:
  name: custom
  version: "tomcli/pytorch:0925mpi"
  command: python -u train_dist_parallel.py --batch_size 1024
