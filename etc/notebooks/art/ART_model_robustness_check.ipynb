{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Adversarial Samples for Deep Learning Models with the Adversarial Robustness Toolbox (ART)\n",
    "\n",
    "This notebook shows how to use adversarial attack techniques from the [Adversarial Robustness Toolbox (ART)](https://developer.ibm.com/code/open/projects/adversarial-robustness-toolbox/) on Deep Learning models trained with *FfDL*. The *ART* library supports crafting and analyzing various attack and defense methods for deep learning models. \n",
    "\n",
    "In this notebook, you will learn how to incorporate one of the attack methods supported by *ART*, the *Fast Gradient Method* (*FGM*), into your training pipeline to generate adversarial samples for the purposes of evaluating the robustness of the trained model. The model is a Convolutional Neural Network (CNN) trained on the *[MNIST handwritten digit data](http://yann.lecun.com/exdb/mnist/)* using [Keras](https://keras.io/) with a [TensorFlow](https://www.tensorflow.org/) backend.\n",
    "\n",
    "The *ART* Github repository can be found here - https://github.com/IBM/adversarial-robustness-toolbox\n",
    "\n",
    "This notebook uses Python 3.\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "1.\t[Set up the environment](#setup)\n",
    "2.\t[Create a Keras model](#model)\n",
    "3.  [Train the model](#train)\n",
    "4.\t[Generate adversarial samples for a robustness check](#art)\n",
    "5.\t[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup\n",
    "\n",
    "It is recommended that you run this notebook inside a Python 3 virtual environment. Make sure you have all required libraries installed.\n",
    "\n",
    "To store model and training data, this notebook requires access to a Cloud Object Storage (COS) instance. [BlueMix Cloud Object Storage](https://console.bluemix.net/catalog/services/cloud-object-storage) offers a free *lite plan*. Follow [these instructions](https://dataplatform.ibm.com/docs/content/analyze-data/ml_dlaas_object_store.html) to create your COS instance and generate [service credentials](https://console.bluemix.net/docs/services/cloud-object-storage/iam/service-credentials.html#service-credentials) with [HMAC keys](https://console.bluemix.net/docs/services/cloud-object-storage/hmac/credentials.html#using-hmac-credentials).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enter your cluster and object storage information:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = {\n",
    "    \"ffdl_cluster_name\"          : \"\",    # Name of your Kubernetes cluster with FfDL deployed on it\n",
    "    \"vm_type\"                    : \"\",    # Type of VM your Kubernetes cluster is deployed on ['none'|'minikube'|'ibmcloud']\n",
    "    \"cos_hmac_access_key_id\"     : \"\",    # Cloud Object Storage (AWS) Access Key ID\n",
    "    \"cos_hmac_secret_access_key\" : \"\",    # Cloud Object Storage (AWS) Secret Access Key\n",
    "    \"cos_service_endpoint\"       : \"\",    # Cloud Object Storage endpoint, i.e. 'https://s3-api.us-geo.objectstorage.softlayer.net'\n",
    "    \"cos_region_name\"            : \"\"     # Cloud Object Storage endpoint, i.e. 'us-east-1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unset_vars = [key for (key, value) in user_data.items() if not value]\n",
    "\n",
    "for var in unset_vars:\n",
    "    print(\"Dictionary 'user_data' is missing '%s'\" % var)\n",
    "    \n",
    "assert not unset_vars, \"Enter 'user_data' to run this notebook!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Verify or Install Required Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required libraries are installed.\n",
      "keras>=2.1.6\r\n",
      "tensorflow>=1.8\r\n",
      "ipython>=5.0.0\r\n",
      "jupyter>=1.0.0\r\n",
      "requests>=2.12.0,<=2.18.4\r\n",
      "wget\r\n",
      "boto3\r\n",
      "git+git://github.com/IBM/adversarial-robustness-toolbox@master\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def is_venv():\n",
    "    return (hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix))\n",
    "\n",
    "try:\n",
    "    import keras, tensorflow, requests, wget, boto3, art\n",
    "    print(\"All required libraries are installed.\")\n",
    "    !cat requirements.txt\n",
    "except ModuleNotFoundError:\n",
    "    if is_venv:\n",
    "        print(\"Installing required libraries into virtual environment.\")\n",
    "        !python -m pip install -r requirements.txt\n",
    "    else:\n",
    "        print(\"Please install the required libraries.\")\n",
    "        !cat requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Connect to Cloud Object Storage  (COS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `boto3.resource` to interact with the COS instance. The `boto3` library allows Python developers to manage Cloud Object Storage (COS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = boto3.resource(\"s3\", \n",
    "                     aws_access_key_id     = user_data[\"cos_hmac_access_key_id\"],\n",
    "                     aws_secret_access_key = user_data[\"cos_hmac_secret_access_key\"],\n",
    "                     endpoint_url          = user_data[\"cos_service_endpoint\"],\n",
    "                     region_name           = user_data[\"cos_region_name\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bucket in cos.buckets.all():\n",
    "#     print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two buckets, which you will use to store training data and training results.\n",
    "\n",
    "**Note:** The bucket names must be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bucket \"training-data-3dab62c6-8696-49ac-b4fe-2abba301aa92\" ...\n",
      "Creating bucket \"training-results-3dab62c6-8696-49ac-b4fe-2abba301aa92\" ...\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "bucket_uid             = str(uuid4())\n",
    "training_data_bucket   = 'training-data-' + bucket_uid\n",
    "training_result_bucket = 'training-results-' + bucket_uid\n",
    "\n",
    "def create_buckets(bucket_names):\n",
    "    for bucket in bucket_names:\n",
    "        print('Creating bucket \"{}\" ...'.format(bucket))\n",
    "        try:\n",
    "            cos.create_bucket(Bucket=bucket)\n",
    "        except boto3.exceptions.botocore.client.ClientError as e:\n",
    "            print('Error: {}.'.format(e.response['Error']['Message']))\n",
    "\n",
    "buckets = [training_data_bucket, training_result_bucket]\n",
    "\n",
    "create_buckets(buckets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should have 2 buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Download MNIST Training Data and Upload it to the COS Buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the training data and upload it to the `training-data` bucket.\n",
    "First, create a list of links for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data links\n",
    "data_links = ['https://s3.amazonaws.com/img-datasets/mnist.npz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next cell uploads files from links to your COS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data mnist.npz ...\n",
      "mnist.npz is uploaded.\n"
     ]
    }
   ],
   "source": [
    "# Upload files to COS\n",
    "from urllib.request import urlopen\n",
    "\n",
    "bucket_obj = cos.Bucket(training_data_bucket)\n",
    "\n",
    "for data_link in data_links:\n",
    "    filename = data_link.split('/')[-1]\n",
    "    print('Uploading data {} ...'.format(filename))\n",
    "    with urlopen(data_link) as data:\n",
    "        bucket_obj.upload_fileobj(data, filename)\n",
    "        print('{} is uploaded.'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the list of the created buckets and their contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training-data-3dab62c6-8696-49ac-b4fe-2abba301aa92\n",
      "  File: mnist.npz, 11221.13kB\n",
      "training-results-3dab62c6-8696-49ac-b4fe-2abba301aa92\n"
     ]
    }
   ],
   "source": [
    "def print_bucket_contents(buckets):\n",
    "    for bucket_name in buckets:\n",
    "        print(bucket_name)\n",
    "        bucket_obj = cos.Bucket(bucket_name)\n",
    "        for obj in bucket_obj.objects.all():\n",
    "            print(\"  File: {}, {:4.2f}kB\".format(obj.key, obj.size/1024))\n",
    "\n",
    "print_bucket_contents(buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are done with COS, and you are ready to train your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## 2. Create the Keras model\n",
    "\n",
    "In this section we:\n",
    "\n",
    "- [2.1 Package the model definition](#zip)\n",
    "- [2.2 Prepare the training definition metadata](#manifest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Create the Model Zip File <a id=\"zip\"></a>\n",
    "\n",
    "Let's create the model [`convolutional_keras.py`](../edit/convolutional_keras.py) and add it to a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_filename  = \"convolutional_keras.py\"\n",
    "archive_filename = 'model.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing convolutional_keras.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_filename\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    if len(argv) < 2:\n",
    "        sys.exit(\"Not enough arguments provided.\")\n",
    "    global image_path\n",
    "    i = 1\n",
    "    while i <= 2:\n",
    "        arg = str(argv[i])\n",
    "        if arg == \"--data\":\n",
    "            image_path = os.path.join(os.environ[\"DATA_DIR\"], str(argv[i+1]))\n",
    "        i += 2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv)\n",
    "\n",
    "\n",
    "# load mnist npz file\n",
    "f = np.load(image_path)\n",
    "x_train = f['x_train']\n",
    "y_train = f['y_train']\n",
    "x_test = f['x_test']\n",
    "y_test = f['y_test']\n",
    "f.close()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model_wt_path = os.environ[\"RESULT_DIR\"] + \"/keras_original_model.hdf5\"\n",
    "model.save(model_wt_path)\n",
    "print(\"Model saved to file: %s\" % model_wt_path)\n",
    "\n",
    "model_def_path = os.environ[\"RESULT_DIR\"] + \"/keras_original_model.json\"\n",
    "model_json = model.to_json()\n",
    "with open(model_def_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(\"Model definition saved to file: %s\" % model_def_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: convolutional_keras.py (deflated 60%)\r\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zipfile.ZipFile(archive_filename, mode='w').write(script_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Prepare the Training Definition Metadata <a id=\"manifest\"></a>\n",
    "- *FfDL* does not have a *Keras* community image so we need to `pip`-install *Keras* prior to running the `training_command` \n",
    "- Your COS credentials are referenced in the `data_stores` > `connection` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "training_command = \"pip3 install keras; python3 convolutional_keras.py --data ${DATA_DIR}/mnist.npz\"\n",
    "\n",
    "manifest = {\n",
    "  \"name\": \"keras_digit_recognition\",\n",
    "  \"description\": \"Hand-written Digit Recognition Training\",\n",
    "  \"version\": \"1.0\",\n",
    "  \"gpus\": 0,\n",
    "  \"cpus\": 2,\n",
    "  \"memory\": \"2Gb\",\n",
    "  \"data_stores\": [\n",
    "    {\n",
    "      \"id\": \"sl-internal-os\",\n",
    "      \"type\": \"s3_datastore\",\n",
    "      \"training_data\": {\n",
    "        \"container\": training_data_bucket\n",
    "      },\n",
    "      \"training_results\": {\n",
    "        \"container\": training_result_bucket\n",
    "      },\n",
    "      \"connection\": {\n",
    "        \"type\": \"s3_datastore\",\n",
    "        \"auth_url\":  user_data[\"cos_service_endpoint\"],\n",
    "        \"user_name\": user_data[\"cos_hmac_access_key_id\"],\n",
    "        \"password\":  user_data[\"cos_hmac_secret_access_key\"]\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"framework\": {\n",
    "    \"name\": \"tensorflow\",\n",
    "    \"version\": \"1.5.0-py3\",\n",
    "    \"command\": training_command\n",
    "  },\n",
    "  \"evaluation_metrics\": {\n",
    "    \"type\": \"tensorboard\",\n",
    "    \"in\": \"$JOB_STATE_DIR/logs/tb\"\n",
    "  }\n",
    "}\n",
    "\n",
    "yaml.dump(manifest, open(\"manifest.yml\", \"w\"), default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model<a id=\"train\"></a>\n",
    "\n",
    "In this section, learn how to:\n",
    "- [3.1 Setup the command line environment](#cmd_setup)\n",
    "- [3.2 Train the model in the background](#backg)\n",
    "- [3.3 Monitor the training log](#log)\n",
    "- [3.4 Cancel the training](#cancel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Setup the Command Line Environment <a id=\"cmd_setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Kubernetes cluster configuration using the [BlueMix CLI](https://console.bluemix.net/docs/cli/index.html#overview). Make sure your machine is logged in with `bx login`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: VM_TYPE=ibmcloud\n",
      "env: CLUSTER_NAME=ffdl-with-art-cluster\n",
      "env: KUBECONFIG=~.bluemix/plugins/container-service/clusters/ffdl-with-art-cluster/kube-config-dal12-ffdl-with-art-cluster.yml\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %env VM_TYPE      {user_data[\"vm_type\"]}\n",
    "    %env CLUSTER_NAME {user_data[\"ffdl_cluster_name\"]}\n",
    "    cluster_config  = !bx cs cluster-config {user_data[\"ffdl_cluster_name\"]} | grep \"export KUBECONFIG=\"\n",
    "    %env KUBECONFIG   {cluster_config[-1].split(\"=\")[-1]}\n",
    "except IndexError:\n",
    "    print(\"The cluster %s could not be found.\" % {user_data[\"ffdl_cluster_name\"]})\n",
    "    print(\"Run 'bx cs clusters' to list all clusters you have access to.\")\n",
    "    #!bx cs clusters\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the DLaaS URL, username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DLAAS_URL=http://169.48.201.210:30020\n",
      "env: DLAAS_USERNAME=test-user\n",
      "env: DLAAS_PASSWORD=test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "notebook_dir   = os.getcwd()\n",
    "ffdl_root_dir  = notebook_dir.replace(\"/etc/notebooks/art\", \"\")\n",
    "node_ip        = !(cd {ffdl_root_dir} && make --no-print-directory kubernetes-ip)\n",
    "restapi_port   = !kubectl get service ffdl-restapi -o jsonpath='{.spec.ports[0].nodePort}'\n",
    "dlaas_url      = \"http://%s:%s\" % (node_ip[0], restapi_port[0])\n",
    "\n",
    "%env DLAAS_URL        $dlaas_url\n",
    "%env DLAAS_USERNAME = test-user\n",
    "%env DLAAS_PASSWORD = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the correct FfDL CLI for your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "ffdl = \"%s/cli/bin/ffdl-%s\" % (ffdl_root_dir, \"osx\" if platform.system() == \"Darwin\" else \"linux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Start the Training Job<a id=\"backg\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Deploying model with manifest 'manifest.yml' and model file 'model.zip'...\",\n",
       " 'Model ID: training-vIIKNQIiR',\n",
       " 'OK']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = !{ffdl} train \"manifest.yml\" \"model.zip\"\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.  Monitor the Training Logs<a id=\"log\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting model training logs for '\u001b[1;36mtraining-vIIKNQIiR\u001b[0m'...\n",
      "Status: PENDING\n",
      "Status: Not Started\n",
      "Training with training/test data at:\n",
      "  DATA_DIR: /job/training-data-3dab62c6-8696-49ac-b4fe-2abba301aa92\n",
      "  MODEL_DIR: /job/model-code\n",
      "  TRAINING_JOB: \n",
      "  TRAINING_COMMAND: pip3 install keras; python3 convolutional_keras.py --data ${DATA_DIR}/mnist.npz\n",
      "Storing trained model at:\n",
      "  RESULT_DIR: /job/training-results-3dab62c6-8696-49ac-b4fe-2abba301aa92\n",
      "Contents of $MODEL_DIR\n",
      "total 12\n",
      "drwxrwxrwx 2 6342627 root 4096 Jun 11 04:02 .\n",
      "drwxrwxrwx 6 root    root 4096 Jun 11 04:02 ..\n",
      "-rwxrwxrwx 1 6342627 root 2649 Jun 10 21:00 convolutional_keras.py\n",
      "Contents of $DATA_DIR\n",
      "total 11232\n",
      "drwxr-xr-x 2 6342627 root     4096 Jun 11 04:02 .\n",
      "drwxrwxrwx 6 root    root     4096 Jun 11 04:02 ..\n",
      "-rw-r--r-- 1 6342627 root 11490434 Jun 11 04:00 mnist.npz\n",
      "DATA_DIR=/job/training-data-3dab62c6-8696-49ac-b4fe-2abba301aa92\n",
      "ELASTICSEARCH_PORT=tcp://172.21.40.112:9200\n",
      "ELASTICSEARCH_PORT_9200_TCP=tcp://172.21.40.112:9200\n",
      "ELASTICSEARCH_PORT_9200_TCP_ADDR=172.21.40.112\n",
      "ELASTICSEARCH_PORT_9200_TCP_PORT=9200\n",
      "ELASTICSEARCH_PORT_9200_TCP_PROTO=tcp\n",
      "ELASTICSEARCH_SERVICE_HOST=172.21.40.112\n",
      "ELASTICSEARCH_SERVICE_PORT=9200\n",
      "ELASTICSEARCH_SERVICE_PORT_HTTP=9200\n",
      "FFDL_LCM_PORT=tcp://172.21.112.20:80\n",
      "FFDL_LCM_PORT_80_TCP=tcp://172.21.112.20:80\n",
      "FFDL_LCM_PORT_80_TCP_ADDR=172.21.112.20\n",
      "FFDL_LCM_PORT_80_TCP_PORT=80\n",
      "FFDL_LCM_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_LCM_SERVICE_HOST=172.21.112.20\n",
      "FFDL_LCM_SERVICE_PORT=80\n",
      "FFDL_LCM_SERVICE_PORT_GRPC=80\n",
      "FFDL_RESTAPI_PORT=tcp://172.21.130.217:80\n",
      "FFDL_RESTAPI_PORT_80_TCP=tcp://172.21.130.217:80\n",
      "FFDL_RESTAPI_PORT_80_TCP_ADDR=172.21.130.217\n",
      "FFDL_RESTAPI_PORT_80_TCP_PORT=80\n",
      "FFDL_RESTAPI_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_RESTAPI_SERVICE_HOST=172.21.130.217\n",
      "FFDL_RESTAPI_SERVICE_PORT=80\n",
      "FFDL_RESTAPI_SERVICE_PORT_FFDL=80\n",
      "FFDL_TRAINER_PORT=tcp://172.21.226.67:80\n",
      "FFDL_TRAINER_PORT_80_TCP=tcp://172.21.226.67:80\n",
      "FFDL_TRAINER_PORT_80_TCP_ADDR=172.21.226.67\n",
      "FFDL_TRAINER_PORT_80_TCP_PORT=80\n",
      "FFDL_TRAINER_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_TRAINER_SERVICE_HOST=172.21.226.67\n",
      "FFDL_TRAINER_SERVICE_PORT=80\n",
      "FFDL_TRAINER_SERVICE_PORT_GRPC=80\n",
      "FFDL_TRAININGDATA_PORT=tcp://172.21.106.158:80\n",
      "FFDL_TRAININGDATA_PORT_80_TCP=tcp://172.21.106.158:80\n",
      "FFDL_TRAININGDATA_PORT_80_TCP_ADDR=172.21.106.158\n",
      "FFDL_TRAININGDATA_PORT_80_TCP_PORT=80\n",
      "FFDL_TRAININGDATA_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_TRAININGDATA_SERVICE_HOST=172.21.106.158\n",
      "FFDL_TRAININGDATA_SERVICE_PORT=80\n",
      "FFDL_TRAININGDATA_SERVICE_PORT_GRPC=80\n",
      "FFDL_UI_PORT=tcp://172.21.201.22:80\n",
      "FFDL_UI_PORT_80_TCP=tcp://172.21.201.22:80\n",
      "FFDL_UI_PORT_80_TCP_ADDR=172.21.201.22\n",
      "FFDL_UI_PORT_80_TCP_PORT=80\n",
      "FFDL_UI_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_UI_SERVICE_HOST=172.21.201.22\n",
      "FFDL_UI_SERVICE_PORT=80\n",
      "FFDL_UI_SERVICE_PORT_HTTP=80\n",
      "GPU_COUNT=0.000000\n",
      "HOME=/root\n",
      "JOB_STATE_DIR=/job\n",
      "LEARNER_ID=1\n",
      "LOG_DIR=/job/logs\n",
      "MODEL_DIR=/job/model-code\n",
      "OLDPWD=/notebooks\n",
      "PATH=/usr/local/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "PROMETHEUS_PORT=tcp://172.21.53.216:9090\n",
      "PROMETHEUS_PORT_9090_TCP=tcp://172.21.53.216:9090\n",
      "PROMETHEUS_PORT_9090_TCP_ADDR=172.21.53.216\n",
      "PROMETHEUS_PORT_9090_TCP_PORT=9090\n",
      "PROMETHEUS_PORT_9090_TCP_PROTO=tcp\n",
      "PROMETHEUS_SERVICE_HOST=172.21.53.216\n",
      "PROMETHEUS_SERVICE_PORT=9090\n",
      "PROMETHEUS_SERVICE_PORT_PROMETHEUS=9090\n",
      "PWD=/job/model-code\n",
      "PYTHONPATH=:/job/model-code\n",
      "RESULT_DIR=/job/training-results-3dab62c6-8696-49ac-b4fe-2abba301aa92\n",
      "S3_PORT=tcp://172.21.95.18:80\n",
      "S3_PORT_80_TCP=tcp://172.21.95.18:80\n",
      "S3_PORT_80_TCP_ADDR=172.21.95.18\n",
      "S3_PORT_80_TCP_PORT=80\n",
      "S3_PORT_80_TCP_PROTO=tcp\n",
      "S3_SERVICE_HOST=172.21.95.18\n",
      "S3_SERVICE_PORT=80\n",
      "SHLVL=3\n",
      "TRAINING_COMMAND=pip3 install keras; python3 convolutional_keras.py --data ${DATA_DIR}/mnist.npz\n",
      "TRAINING_ID=training-vIIKNQIiR\n",
      "_=/usr/bin/env\n",
      "Mon Jun 11 04:02:13 UTC 2018: Running training job\n",
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/68/12/4cabc5c01451eb3b413d19ea151f36e33026fc0efb932bf51bcaf54acbf5/Keras-2.2.0-py2.py3-none-any.whl (300kB)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Collecting keras-preprocessing==1.0.1 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Collecting keras-applications==1.0.2 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/60/c557075e586e968d7a9c314aa38c236b37cb3ee6b37e8d57152b1a5e0b47/Keras_Applications-1.0.2-py2.py3-none-any.whl (43kB)\n",
      "Collecting pyyaml (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/85/db5a2df477072b2902b0eb892feb37d88ac635d36245a72a6a69b23b383a/PyYAML-3.12.tar.gz (253kB)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml: started\n",
      "  Running setup.py bdist_wheel for pyyaml: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/05/65/bdc14f2c6e09e82ae3e0f13d021e1b6b2481437ea2f207df3f\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: keras-preprocessing, keras-applications, pyyaml, keras\n",
      "Successfully installed keras-2.2.0 keras-applications-1.0.2 keras-preprocessing-1.0.1 pyyaml-3.12\n",
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "2018-06-11 04:02:19.065097: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "\n",
      "  128/54000 [..............................] - ETA: 6:03 - loss: 2.3382 - acc: 0.0469\n",
      "  256/54000 [..............................] - ETA: 5:10 - loss: 2.2959 - acc: 0.1172\n",
      "  384/54000 [..............................] - ETA: 4:58 - loss: 2.2550 - acc: 0.1328\n",
      "  512/54000 [..............................] - ETA: 4:45 - loss: 2.2072 - acc: 0.1875\n",
      "  640/54000 [..............................] - ETA: 4:33 - loss: 2.1548 - acc: 0.2156\n",
      "  768/54000 [..............................] - ETA: 4:28 - loss: 2.0889 - acc: 0.2487\n",
      "  896/54000 [..............................] - ETA: 4:26 - loss: 2.0252 - acc: 0.2835\n",
      " 1024/54000 [..............................] - ETA: 4:25 - loss: 2.0009 - acc: 0.2939\n",
      " 1152/54000 [..............................] - ETA: 4:22 - loss: 1.9649 - acc: 0.3134\n",
      " 1280/54000 [..............................] - ETA: 4:21 - loss: 1.9351 - acc: 0.3273\n",
      " 1408/54000 [..............................] - ETA: 4:19 - loss: 1.8885 - acc: 0.3423\n",
      " 1536/54000 [..............................] - ETA: 4:17 - loss: 1.8577 - acc: 0.3555\n",
      " 1664/54000 [..............................] - ETA: 4:16 - loss: 1.8253 - acc: 0.3744\n",
      " 1792/54000 [..............................] - ETA: 4:14 - loss: 1.7967 - acc: 0.3834\n",
      " 1920/54000 [>.............................] - ETA: 4:13 - loss: 1.7511 - acc: 0.4031\n",
      " 2048/54000 [>.............................] - ETA: 4:12 - loss: 1.6997 - acc: 0.4224\n",
      " 2176/54000 [>.............................] - ETA: 4:11 - loss: 1.6624 - acc: 0.4343\n",
      " 2304/54000 [>.............................] - ETA: 4:10 - loss: 1.6430 - acc: 0.4405\n",
      " 2432/54000 [>.............................] - ETA: 4:09 - loss: 1.6111 - acc: 0.4519\n",
      " 2560/54000 [>.............................] - ETA: 4:08 - loss: 1.5762 - acc: 0.4641\n",
      " 2688/54000 [>.............................] - ETA: 4:07 - loss: 1.5409 - acc: 0.4777\n",
      " 2816/54000 [>.............................] - ETA: 4:06 - loss: 1.5126 - acc: 0.4883\n",
      " 2944/54000 [>.............................] - ETA: 4:05 - loss: 1.4870 - acc: 0.4966\n",
      " 3072/54000 [>.............................] - ETA: 4:04 - loss: 1.4598 - acc: 0.5072\n",
      " 3200/54000 [>.............................] - ETA: 4:04 - loss: 1.4294 - acc: 0.5194\n",
      " 3328/54000 [>.............................] - ETA: 4:03 - loss: 1.4010 - acc: 0.5300\n",
      " 3456/54000 [>.............................] - ETA: 4:02 - loss: 1.3822 - acc: 0.5373\n",
      " 3584/54000 [>.............................] - ETA: 4:01 - loss: 1.3540 - acc: 0.5488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52992/54000 [============================>.] - ETA: 4s - loss: 0.3059 - acc: 0.9054\n",
      "53120/54000 [============================>.] - ETA: 4s - loss: 0.3056 - acc: 0.9055\n",
      "53248/54000 [============================>.] - ETA: 3s - loss: 0.3053 - acc: 0.9056\n",
      "53376/54000 [============================>.] - ETA: 2s - loss: 0.3048 - acc: 0.9058\n",
      "53504/54000 [============================>.] - ETA: 2s - loss: 0.3044 - acc: 0.9059\n",
      "53632/54000 [============================>.] - ETA: 1s - loss: 0.3039 - acc: 0.9060\n",
      "53760/54000 [============================>.] - ETA: 1s - loss: 0.3036 - acc: 0.9061\n",
      "53888/54000 [============================>.] - ETA: 0s - loss: 0.3030 - acc: 0.9063\n",
      "54000/54000 [==============================] - 263s 5ms/step - loss: 0.3028 - acc: 0.9064 - val_loss: 0.0592 - val_acc: 0.9835\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Test loss: 0.06394996056337841\n",
      "Test accuracy: 0.978\n",
      "Model saved to file: /job/training-results-3dab62c6-8696-49ac-b4fe-2abba301aa92/keras_original_model.hdf5\n",
      "Model definition saved to file: /job/training-results-3dab62c6-8696-49ac-b4fe-2abba301aa92/keras_original_model.json\n",
      "Training process finished. Exit code: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if \"Model ID\" in out[1]:\n",
    "    model_id = out.fields()[1][-1]\n",
    "    !{ffdl} logs --follow {model_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Adversarial Samples <a id=\"art\"></a>\n",
    "\n",
    "In this section, we learn how to:\n",
    "- [4.1 Generate adversarial samples with ART (synchronously in notebook)](#artLocal)\n",
    "- [4.2 Generate adversarial samples with ART (asynchronously using FfDL)](#artWithFfDL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Generate Adversarial Samples Locally <a id=\"artLocal\"></a>\n",
    "\n",
    "This section shows how to use the ART Fast Gradient Method (FGM) to generate adversarial samples for the model previously trained synchronously in this notebook. \n",
    "\n",
    "A trained model should have been created in the `training_result_bucket`. Now ART can be used to check the robustness of the trained model. \n",
    "\n",
    "The original dataset used to train the model as well as the trained model serve as inputs to the `robustness_check.py` script. We can download both from the `training_data_bucket` and the `training_result_bucket` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the original data set and the trained model from Cloud Object Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = \"mnist.npz\"\n",
    "weights_filename = \"keras_original_model.hdf5\"\n",
    "network_definition_filename = \"keras_original_model.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print contents of COS buckets used in the previous training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training-data-3dab62c6-8696-49ac-b4fe-2abba301aa92\n",
      "  File: mnist.npz, 11221.13kB\n",
      "training-results-3dab62c6-8696-49ac-b4fe-2abba301aa92\n",
      "  File: training-vIIKNQIiR/keras_original_model.hdf5, 14092.55kB\n",
      "  File: training-vIIKNQIiR/keras_original_model.json, 2.75kB\n",
      "  File: training-vIIKNQIiR/learner-1/load-data.log, 3.39kB\n",
      "  File: training-vIIKNQIiR/learner-1/load-model.log, 0.42kB\n",
      "  File: training-vIIKNQIiR/learner-1/training-log.txt, 41.58kB\n"
     ]
    }
   ],
   "source": [
    "print_bucket_contents([training_data_bucket, training_result_bucket])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded keras_original_model.hdf5\n",
      "Downloaded keras_original_model.json\n"
     ]
    }
   ],
   "source": [
    "# download network definition and weights to current working directory\n",
    "\n",
    "weights_file_in_cos_bucket = os.path.join(model_id, weights_filename)\n",
    "network_definition_file_in_cos_bucket = os.path.join(model_id, network_definition_filename)\n",
    "\n",
    "bucket_obj = cos.Bucket(training_result_bucket)\n",
    "\n",
    "bucket_obj.download_file(weights_file_in_cos_bucket, weights_filename)\n",
    "print('Downloaded', weights_filename)\n",
    "\n",
    "bucket_obj.download_file(network_definition_file_in_cos_bucket, network_definition_filename)\n",
    "print('Downloaded', network_definition_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the original data set (mnist.npz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded mnist.npz\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "bucket_obj = cos.Bucket(training_data_bucket)\n",
    "bucket_obj.download_file(dataset_filename, dataset_filename)\n",
    "print('Downloaded', dataset_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load & compile the model that we created using `convolutional_keras.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Definition: keras_original_model.json\n",
      "Weights:            keras_original_model.hdf5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json\n",
    "\n",
    "print('Network Definition:', network_definition_filename)\n",
    "print('Weights:           ', weights_filename)\n",
    "\n",
    "# load model\n",
    "json_file = open(network_definition_filename, 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(weights_filename)\n",
    "comp_params = {'loss': 'categorical_crossentropy',\n",
    "                       'optimizer': 'adam',\n",
    "                       'metrics': ['accuracy']}\n",
    "model.compile(**comp_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading & compiling the model, the next step is to create a KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ART classifier object\n",
    "from art.classifiers.keras import KerasClassifier\n",
    "\n",
    "classifier = KerasClassifier((0, 1), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test data and labels from `mnist.npz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "f = np.load(dataset_filename)\n",
    "x_original = f['x_test']\n",
    "y = f['y_test']\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the original (non-adversarial) sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(x_original[1], cmap='gray')\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "x_original = np.expand_dims(x_original, axis=3)\n",
    "x_original = x_original.astype('float32') / 255\n",
    "y = np_utils.to_categorical(y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model and calculated test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model test loss:     6.394996068091132\n",
      "model test accuracy: 97.8\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "scores = model.evaluate(x_original, y, verbose=0)\n",
    "print('model test loss:    ', scores[0]*100)\n",
    "print('model test accuracy:', scores[1]*100)\n",
    "model_accuracy = scores[1]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ART exposes many attacks like FGM, NewtonFool, DeepFool, Carlini etc. The code below shows how to use one of ART's attack methods (Fast Gradient Method or FGM) to craft adversarial samples based on x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of adversarial samples crafted: 10000\n",
      "adversarial samples saved to: etc/notebooks/art/adv_samples\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.fast_gradient import FastGradientMethod\n",
    "\n",
    "# configuration\n",
    "epsilon = 0.2\n",
    "\n",
    "# create crafter object\n",
    "crafter = FastGradientMethod(classifier, eps=epsilon)\n",
    "\n",
    "# craft samples on x_test (stored in variable x_original)\n",
    "x_adv_samples = crafter.generate(x_original)\n",
    "\n",
    "outfile = os.path.join(os.getcwd(), 'adv_samples')\n",
    "np.savez(outfile, x_original=x_original, x_adversarial=x_adv_samples, y=y)\n",
    "\n",
    "print(\"Number of adversarial samples crafted:\", len(x_adv_samples))\n",
    "print(\"adversarial samples saved to:\", outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions can be used for gathering metrics like model robustness, confidence metric, perturbation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as la\n",
    "import json\n",
    "\n",
    "\n",
    "def get_metrics(model, x_original, x_adv_samples, y):\n",
    "    scores = model.evaluate(x_original, y, verbose=0)\n",
    "    model_accuracy_on_non_adversarial_samples = scores[1] * 100\n",
    "\n",
    "    y_pred = model.predict(x_original, verbose=0)\n",
    "    y_pred_adv = model.predict(x_adv_samples, verbose=0)\n",
    "\n",
    "    scores = model.evaluate(x_adv_samples, y, verbose=0)\n",
    "    model_accuracy_on_adversarial_samples = scores[1] * 100\n",
    "\n",
    "    pert_metric = get_perturbation_metric(x_original, x_adv_samples, y_pred, y_pred_adv, ord=2)\n",
    "    conf_metric = get_confidence_metric(y_pred, y_pred_adv)\n",
    "\n",
    "    data = {\n",
    "        \"model accuracy on test data:\": model_accuracy_on_non_adversarial_samples,\n",
    "        \"model accuracy on adversarial samples\": model_accuracy_on_adversarial_samples,\n",
    "        \"reduction in confidence\": conf_metric * 100,\n",
    "        \"average perturbation\": pert_metric * 100\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_perturbation_metric(x_original, x_adv, y_pred, y_pred_adv, ord=2):\n",
    "\n",
    "    idxs = (np.argmax(y_pred_adv, axis=1) != np.argmax(y_pred, axis=1))\n",
    "\n",
    "    if np.sum(idxs) == 0.0:\n",
    "        return 0\n",
    "\n",
    "    perts_norm = la.norm((x_adv - x_original).reshape(x_original.shape[0], -1), ord, axis=1)\n",
    "    perts_norm = perts_norm[idxs]\n",
    "\n",
    "    return np.mean(perts_norm / la.norm(x_original[idxs].reshape(np.sum(idxs), -1), ord, axis=1))\n",
    "\n",
    "\n",
    "# This computes the change in confidence for all images in the test set\n",
    "def get_confidence_metric(y_pred, y_pred_adv):\n",
    "\n",
    "    y_classidx = np.argmax(y_pred, axis=1)\n",
    "    y_classconf = y_pred[np.arange(y_pred.shape[0]), y_classidx]\n",
    "\n",
    "    y_adv_classidx = np.argmax(y_pred_adv, axis=1)\n",
    "    y_adv_classconf = y_pred_adv[np.arange(y_pred_adv.shape[0]), y_adv_classidx]\n",
    "\n",
    "    idxs = (y_classidx == y_adv_classidx)\n",
    "\n",
    "    if np.sum(idxs) == 0.0:\n",
    "        return 0\n",
    "\n",
    "    idxnonzero = y_classconf != 0\n",
    "    idxs = idxs & idxnonzero\n",
    "\n",
    "    return np.mean((y_classconf[idxs] - y_adv_classconf[idxs]) / y_classconf[idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will display the following\n",
    "\n",
    "1. Model accuracy on test data\n",
    "2. Model robustness on adversarial samples\n",
    "3. Reduction in confidence\n",
    "4. Perturbation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \n",
      "    \"model accuracy on test data:\": 97.8,\n",
      "    \"model accuracy on adversarial samples\": 41.85,\n",
      "    \"reduction in confidence\": 29.16172742843628\n",
      "    \"average perturbation\": 47.15782701969147,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = get_metrics(model, x_original, x_adv_samples, y)\n",
    "\n",
    "print(json.dumps(result, indent=4, sort_keys=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the numpy array, so that the adversarial images can be visualized\n",
    "\n",
    "x_adv = (x_adv_samples * 255).astype('int')\n",
    "x_adv = x_adv[:, :, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize an adversarial sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_adv[1], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Generate Adversarial Samples Asynchronously using FfDL <a id=\"artWithFfDL\"></a>\n",
    "\n",
    "As its name suggests, FGM is a relatively short running method to generate adversarial samples. Other attack techniques can take much longer and therefore you may want to use additional computing resources and generate adversarial samples through an asynchronous Watsom ML training request. This section shows how to gather the relevant information to execute FGM as an asynchronous FfDL training job. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first create two COS buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bucket \"robustnesscheck-data-9b9e2782-4b17-4930-b9a4-bbe4862dc6ca\" ...\n",
      "Creating bucket \"robustnesscheck-results-9b9e2782-4b17-4930-b9a4-bbe4862dc6ca\" ...\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "bucket_uid = str(uuid4())\n",
    "\n",
    "robustnesscheck_data_bucket   = 'robustnesscheck-data-'    + bucket_uid\n",
    "robustnesscheck_result_bucket = 'robustnesscheck-results-' + bucket_uid\n",
    "\n",
    "buckets = [robustnesscheck_data_bucket,\n",
    "           robustnesscheck_result_bucket]\n",
    "\n",
    "create_buckets(buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload all the artifacts (`mnist.npz`, `keras_original_model.json`, `keras_original_model.hdf5`) to the `robustnesscheck_data_bucket`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading files to robustnesscheck-data-9b9e2782-4b17-4930-b9a4-bbe4862dc6ca:\n",
      "- mnist.npz was uploaded\n",
      "- keras_original_model.hdf5 was uploaded\n",
      "- keras_original_model.json was uploaded\n"
     ]
    }
   ],
   "source": [
    "# upload\n",
    "\n",
    "bucket_obj = cos.Bucket(robustnesscheck_data_bucket)\n",
    "print(\"Uploading files to {}:\".format(robustnesscheck_data_bucket))\n",
    "\n",
    "bucket_obj.upload_file(dataset_filename, dataset_filename)\n",
    "print('- {} was uploaded'.format(dataset_filename)) \n",
    "\n",
    "bucket_obj.upload_file(weights_filename, weights_filename)\n",
    "print('- {} was uploaded'.format(weights_filename))\n",
    "\n",
    "bucket_obj.upload_file(network_definition_filename, network_definition_filename)\n",
    "print('- {} was uploaded'.format(network_definition_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create a Python script that generates adversarial samples to check robustness using FGM (Fast Gradient Method) from the ART library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_filename  = \"robustness_check.py\"\n",
    "archive_filename = 'model.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing robustness_check.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_filename\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import json\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from art.classifiers.keras import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from art.attacks.fast_gradient import FastGradientMethod\n",
    "\n",
    "\n",
    "def get_metrics(model, x_original, x_adv_samples, y):\n",
    "    scores = model.evaluate(x_original, y, verbose=0)\n",
    "    model_accuracy_on_non_adversarial_samples = scores[1] * 100\n",
    "\n",
    "    y_pred = model.predict(x_original, verbose=0)\n",
    "    y_pred_adv = model.predict(x_adv_samples, verbose=0)\n",
    "\n",
    "    scores = model.evaluate(x_adv_samples, y, verbose=0)\n",
    "    model_accuracy_on_adversarial_samples = scores[1] * 100\n",
    "\n",
    "    pert_metric = get_perturbation_metric(x_original, x_adv_samples, y_pred, y_pred_adv, ord=2)\n",
    "    conf_metric = get_confidence_metric(y_pred, y_pred_adv)\n",
    "\n",
    "    data = {\n",
    "        \"model accuracy on test data:\": model_accuracy_on_non_adversarial_samples,\n",
    "        \"model accuracy on adversarial samples\": model_accuracy_on_adversarial_samples,\n",
    "        \"reduction in confidence\": conf_metric * 100,\n",
    "        \"average perturbation\": pert_metric * 100\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_perturbation_metric(x_original, x_adv, y_pred, y_pred_adv, ord=2):\n",
    "\n",
    "    idxs = (np.argmax(y_pred_adv, axis=1) != np.argmax(y_pred, axis=1))\n",
    "\n",
    "    if np.sum(idxs) == 0.0:\n",
    "        return 0\n",
    "\n",
    "    perts_norm = la.norm((x_adv - x_original).reshape(x_original.shape[0], -1), ord, axis=1)\n",
    "    perts_norm = perts_norm[idxs]\n",
    "\n",
    "    return np.mean(perts_norm / la.norm(x_original[idxs].reshape(np.sum(idxs), -1), ord, axis=1))\n",
    "\n",
    "\n",
    "# This computes the change in confidence for all images in the test set\n",
    "def get_confidence_metric(y_pred, y_pred_adv):\n",
    "\n",
    "    y_classidx = np.argmax(y_pred, axis=1)\n",
    "    y_classconf = y_pred[np.arange(y_pred.shape[0]), y_classidx]\n",
    "\n",
    "    y_adv_classidx = np.argmax(y_pred_adv, axis=1)\n",
    "    y_adv_classconf = y_pred_adv[np.arange(y_pred_adv.shape[0]), y_adv_classidx]\n",
    "\n",
    "    idxs = (y_classidx == y_adv_classidx)\n",
    "\n",
    "    if np.sum(idxs) == 0.0:\n",
    "        return 0\n",
    "\n",
    "    idxnonzero = y_classconf != 0\n",
    "    idxs = idxs & idxnonzero\n",
    "\n",
    "    return np.mean((y_classconf[idxs] - y_adv_classconf[idxs]) / y_classconf[idxs])\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    if len(argv) < 2:\n",
    "        sys.exit(\"Not enough arguments provided.\")\n",
    "\n",
    "    global network_definition_filename, weights_filename, dataset_filename\n",
    "\n",
    "    i = 1\n",
    "    while i <= 8:\n",
    "        arg = str(argv[i])\n",
    "        print(arg)\n",
    "        if arg == \"--data\":\n",
    "            dataset_filename = os.path.join(os.environ[\"DATA_DIR\"], str(argv[i+1]))\n",
    "        if arg == \"--networkdefinition\":\n",
    "            network_definition_filename = os.path.join(os.environ[\"DATA_DIR\"], str(argv[i+1]))\n",
    "        if arg == \"--weights\":\n",
    "            weights_filename = os.path.join(os.environ[\"DATA_DIR\"], str(argv[i+1]))\n",
    "        if arg == \"--epsilon\":\n",
    "            epsilon = float(argv[i+1])\n",
    "\n",
    "        i += 2\n",
    "\n",
    "    print(\"dataset: \", dataset_filename)\n",
    "    print(\"network definition: \", network_definition_filename)\n",
    "    print(\"weights: \", weights_filename)\n",
    "\n",
    "    # load & compile model\n",
    "    json_file = open(network_definition_filename, 'r')\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(model_json)\n",
    "    model.load_weights(weights_filename)\n",
    "    comp_params = {'loss': 'categorical_crossentropy',\n",
    "                   'optimizer': 'adam',\n",
    "                   'metrics': ['accuracy']}\n",
    "    model.compile(**comp_params)\n",
    "\n",
    "    # create keras classifier\n",
    "    classifier = KerasClassifier((0, 1), model)\n",
    "\n",
    "    # load data set\n",
    "    pf = np.load(dataset_filename)\n",
    "\n",
    "    x = pf['x_test']\n",
    "    y = pf['y_test']\n",
    "\n",
    "    # pre-process numpy array\n",
    "\n",
    "    x = np.expand_dims(x, axis=3)\n",
    "    x = x.astype('float32') / 255\n",
    "\n",
    "    y = np_utils.to_categorical(y, 10)\n",
    "\n",
    "    # craft adversarial samples using FGSM\n",
    "    crafter = FastGradientMethod(classifier, eps=epsilon)\n",
    "    x_samples = crafter.generate(x)\n",
    "\n",
    "    # obtain all metrics (robustness score, perturbation metric, reduction in confidence)\n",
    "    metrics = get_metrics(model, x, x_samples, y)\n",
    "\n",
    "    print(\"metrics : \", metrics)\n",
    "    \n",
    "    report_file = os.path.join(os.environ[\"RESULT_DIR\"], \"report.txt\")\n",
    "\n",
    "    with open(report_file, \"w\") as report:\n",
    "        report.write(json.dumps(metrics))\n",
    "    \n",
    "    adv_samples_file = os.path.join(os.environ[\"RESULT_DIR\"], 'adv_samples')\n",
    "    print(\"adversarial samples saved to : \", adv_samples_file)\n",
    "    np.savez(adv_samples_file, x_original=x, x_adversarial=x_samples, y=y)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a zip archive to package the training script `robustness_check.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: robustness_check.py (deflated 67%)\r\n"
     ]
    }
   ],
   "source": [
    "zipfile.ZipFile(archive_filename, mode='w').write(script_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Model Definition Metadata. \n",
    "\n",
    "The training command now points to `robustness_check.py` and four arguments are passed to the script:\n",
    "\n",
    "1. data (`mnist.npz`)\n",
    "2. networkdefinition (`keras_original_model.json`)\n",
    "3. weights (`keras_original_model.hdf5`)\n",
    "4. epsilon (`0.2` or `0.1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_command = \"\\\n",
    "pip3 install keras; \\\n",
    "pip3 install https://github.com/IBM/adversarial-robustness-toolbox/zipball/master; \\\n",
    "python3 robustness_check.py \\\n",
    "  --epsilon 0.2 \\\n",
    "  --data ${DATA_DIR}/mnist.npz \\\n",
    "  --networkdefinition ${DATA_DIR}/keras_original_model.json \\\n",
    "  --weights ${DATA_DIR}/keras_original_model.hdf5\"\n",
    "\n",
    "manifest = {\n",
    "  \"name\": \"art_robustness_check\",\n",
    "  \"description\": \"Generates adversarial samples to check robustness using FGM\",\n",
    "  \"version\": \"1.0\",\n",
    "  \"gpus\": 0,\n",
    "  \"cpus\": 2,\n",
    "  \"memory\": \"2Gb\",\n",
    "  \"data_stores\": [\n",
    "    {\n",
    "      \"id\": \"sl-internal-os\",\n",
    "      \"type\": \"s3_datastore\",\n",
    "      \"training_data\": {\n",
    "        \"container\": robustnesscheck_data_bucket\n",
    "      },\n",
    "      \"training_results\": {\n",
    "        \"container\": robustnesscheck_result_bucket\n",
    "      },\n",
    "      \"connection\": {\n",
    "        \"type\": \"s3_datastore\",\n",
    "        \"auth_url\":  user_data[\"cos_service_endpoint\"],\n",
    "        \"user_name\": user_data[\"cos_hmac_access_key_id\"],\n",
    "        \"password\":  user_data[\"cos_hmac_secret_access_key\"]\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"framework\": {\n",
    "    \"name\": \"tensorflow\",\n",
    "    \"version\": \"1.5.0-py3\",\n",
    "    \"command\": training_command\n",
    "  },\n",
    "  \"evaluation_metrics\": {\n",
    "    \"type\": \"tensorboard\",\n",
    "    \"in\": \"$JOB_STATE_DIR/logs/tb\"\n",
    "  }\n",
    "}\n",
    "\n",
    "yaml.dump(manifest, open(\"manifest.yml\", \"w\"), default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start the training job with FfDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Deploying model with manifest 'manifest.yml' and model file 'model.zip'...\",\n",
       " 'Model ID: training-YHWQNQSmg',\n",
       " 'OK']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = !{ffdl} train \"manifest.yml\" \"model.zip\"\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting model training logs for '\u001b[1;36mtraining-YHWQNQSmg\u001b[0m'...\n",
      "Status: PENDING\n",
      "Status: Not Started\n",
      "Training with training/test data at:\n",
      "  DATA_DIR: /job/robustnesscheck-data-9b9e2782-4b17-4930-b9a4-bbe4862dc6ca\n",
      "  MODEL_DIR: /job/model-code\n",
      "  TRAINING_JOB: \n",
      "  TRAINING_COMMAND: pip3 install keras; pip3 install https://github.com/IBM/adversarial-robustness-toolbox/zipball/master; python3 robustness_check.py   --epsilon 0.2   --data ${DATA_DIR}/mnist.npz   --networkdefinition ${DATA_DIR}/keras_original_model.json   --weights ${DATA_DIR}/keras_original_model.hdf5\n",
      "Storing trained model at:\n",
      "  RESULT_DIR: /job/robustnesscheck-results-9b9e2782-4b17-4930-b9a4-bbe4862dc6ca\n",
      "Contents of $MODEL_DIR\n",
      "total 16\n",
      "drwxrwxrwx 2 6342627 root 4096 Jun 11 04:09 .\n",
      "drwxrwxrwx 6 root    root 4096 Jun 11 04:10 ..\n",
      "-rwxrwxrwx 1 6342627 root 4442 Jun 10 21:09 robustness_check.py\n",
      "Contents of $DATA_DIR\n",
      "total 25332\n",
      "drwxr-xr-x 2 6342627 root     4096 Jun 11 04:09 .\n",
      "drwxrwxrwx 6 root    root     4096 Jun 11 04:10 ..\n",
      "-rw-r--r-- 1 6342627 root 14430768 Jun 11 04:08 keras_original_model.hdf5\n",
      "-rw-r--r-- 1 6342627 root     2813 Jun 11 04:09 keras_original_model.json\n",
      "-rw-r--r-- 1 6342627 root 11490434 Jun 11 04:08 mnist.npz\n",
      "DATA_DIR=/job/robustnesscheck-data-9b9e2782-4b17-4930-b9a4-bbe4862dc6ca\n",
      "ELASTICSEARCH_PORT=tcp://172.21.40.112:9200\n",
      "ELASTICSEARCH_PORT_9200_TCP=tcp://172.21.40.112:9200\n",
      "ELASTICSEARCH_PORT_9200_TCP_ADDR=172.21.40.112\n",
      "ELASTICSEARCH_PORT_9200_TCP_PORT=9200\n",
      "ELASTICSEARCH_PORT_9200_TCP_PROTO=tcp\n",
      "ELASTICSEARCH_SERVICE_HOST=172.21.40.112\n",
      "ELASTICSEARCH_SERVICE_PORT=9200\n",
      "ELASTICSEARCH_SERVICE_PORT_HTTP=9200\n",
      "FFDL_LCM_PORT=tcp://172.21.112.20:80\n",
      "FFDL_LCM_PORT_80_TCP=tcp://172.21.112.20:80\n",
      "FFDL_LCM_PORT_80_TCP_ADDR=172.21.112.20\n",
      "FFDL_LCM_PORT_80_TCP_PORT=80\n",
      "FFDL_LCM_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_LCM_SERVICE_HOST=172.21.112.20\n",
      "FFDL_LCM_SERVICE_PORT=80\n",
      "FFDL_LCM_SERVICE_PORT_GRPC=80\n",
      "FFDL_RESTAPI_PORT=tcp://172.21.130.217:80\n",
      "FFDL_RESTAPI_PORT_80_TCP=tcp://172.21.130.217:80\n",
      "FFDL_RESTAPI_PORT_80_TCP_ADDR=172.21.130.217\n",
      "FFDL_RESTAPI_PORT_80_TCP_PORT=80\n",
      "FFDL_RESTAPI_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_RESTAPI_SERVICE_HOST=172.21.130.217\n",
      "FFDL_RESTAPI_SERVICE_PORT=80\n",
      "FFDL_RESTAPI_SERVICE_PORT_FFDL=80\n",
      "FFDL_TRAINER_PORT=tcp://172.21.226.67:80\n",
      "FFDL_TRAINER_PORT_80_TCP=tcp://172.21.226.67:80\n",
      "FFDL_TRAINER_PORT_80_TCP_ADDR=172.21.226.67\n",
      "FFDL_TRAINER_PORT_80_TCP_PORT=80\n",
      "FFDL_TRAINER_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_TRAINER_SERVICE_HOST=172.21.226.67\n",
      "FFDL_TRAINER_SERVICE_PORT=80\n",
      "FFDL_TRAINER_SERVICE_PORT_GRPC=80\n",
      "FFDL_TRAININGDATA_PORT=tcp://172.21.106.158:80\n",
      "FFDL_TRAININGDATA_PORT_80_TCP=tcp://172.21.106.158:80\n",
      "FFDL_TRAININGDATA_PORT_80_TCP_ADDR=172.21.106.158\n",
      "FFDL_TRAININGDATA_PORT_80_TCP_PORT=80\n",
      "FFDL_TRAININGDATA_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_TRAININGDATA_SERVICE_HOST=172.21.106.158\n",
      "FFDL_TRAININGDATA_SERVICE_PORT=80\n",
      "FFDL_TRAININGDATA_SERVICE_PORT_GRPC=80\n",
      "FFDL_UI_PORT=tcp://172.21.201.22:80\n",
      "FFDL_UI_PORT_80_TCP=tcp://172.21.201.22:80\n",
      "FFDL_UI_PORT_80_TCP_ADDR=172.21.201.22\n",
      "FFDL_UI_PORT_80_TCP_PORT=80\n",
      "FFDL_UI_PORT_80_TCP_PROTO=tcp\n",
      "FFDL_UI_SERVICE_HOST=172.21.201.22\n",
      "FFDL_UI_SERVICE_PORT=80\n",
      "FFDL_UI_SERVICE_PORT_HTTP=80\n",
      "GPU_COUNT=0.000000\n",
      "HOME=/root\n",
      "JOB_STATE_DIR=/job\n",
      "LEARNER_ID=1\n",
      "LOG_DIR=/job/logs\n",
      "MODEL_DIR=/job/model-code\n",
      "OLDPWD=/notebooks\n",
      "PATH=/usr/local/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "PROMETHEUS_PORT=tcp://172.21.53.216:9090\n",
      "PROMETHEUS_PORT_9090_TCP=tcp://172.21.53.216:9090\n",
      "PROMETHEUS_PORT_9090_TCP_ADDR=172.21.53.216\n",
      "PROMETHEUS_PORT_9090_TCP_PORT=9090\n",
      "PROMETHEUS_PORT_9090_TCP_PROTO=tcp\n",
      "PROMETHEUS_SERVICE_HOST=172.21.53.216\n",
      "PROMETHEUS_SERVICE_PORT=9090\n",
      "PROMETHEUS_SERVICE_PORT_PROMETHEUS=9090\n",
      "PWD=/job/model-code\n",
      "PYTHONPATH=:/job/model-code\n",
      "RESULT_DIR=/job/robustnesscheck-results-9b9e2782-4b17-4930-b9a4-bbe4862dc6ca\n",
      "S3_PORT=tcp://172.21.95.18:80\n",
      "S3_PORT_80_TCP=tcp://172.21.95.18:80\n",
      "S3_PORT_80_TCP_ADDR=172.21.95.18\n",
      "S3_PORT_80_TCP_PORT=80\n",
      "S3_PORT_80_TCP_PROTO=tcp\n",
      "S3_SERVICE_HOST=172.21.95.18\n",
      "S3_SERVICE_PORT=80\n",
      "SHLVL=3\n",
      "TRAINING_COMMAND=pip3 install keras; pip3 install https://github.com/IBM/adversarial-robustness-toolbox/zipball/master; python3 robustness_check.py   --epsilon 0.2   --data ${DATA_DIR}/mnist.npz   --networkdefinition ${DATA_DIR}/keras_original_model.json   --weights ${DATA_DIR}/keras_original_model.hdf5\n",
      "TRAINING_ID=training-YHWQNQSmg\n",
      "_=/usr/bin/env\n",
      "Mon Jun 11 04:10:02 UTC 2018: Running training job\n",
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/68/12/4cabc5c01451eb3b413d19ea151f36e33026fc0efb932bf51bcaf54acbf5/Keras-2.2.0-py2.py3-none-any.whl (300kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Collecting keras-preprocessing==1.0.1 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
      "Collecting pyyaml (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/85/db5a2df477072b2902b0eb892feb37d88ac635d36245a72a6a69b23b383a/PyYAML-3.12.tar.gz (253kB)\n",
      "Collecting keras-applications==1.0.2 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/60/c557075e586e968d7a9c314aa38c236b37cb3ee6b37e8d57152b1a5e0b47/Keras_Applications-1.0.2-py2.py3-none-any.whl (43kB)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml: started\n",
      "  Running setup.py bdist_wheel for pyyaml: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/05/65/bdc14f2c6e09e82ae3e0f13d021e1b6b2481437ea2f207df3f\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: keras-preprocessing, pyyaml, keras-applications, keras\n",
      "Successfully installed keras-2.2.0 keras-applications-1.0.2 keras-preprocessing-1.0.1 pyyaml-3.12\n",
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "Collecting https://github.com/IBM/adversarial-robustness-toolbox/zipball/master\n",
      "  Downloading https://github.com/IBM/adversarial-robustness-toolbox/zipball/master\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.5/dist-packages (from adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.5/dist-packages (from adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.5/dist-packages (from adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from h5py->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.5/dist-packages (from h5py->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: keras-preprocessing==1.0.1 in /usr/local/lib/python3.5/dist-packages (from Keras->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: keras-applications==1.0.2 in /usr/local/lib/python3.5/dist-packages (from Keras->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from Keras->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.5/dist-packages (from matplotlib->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.5/dist-packages (from matplotlib->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib->adversarial-robustness-toolbox==0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib->adversarial-robustness-toolbox==0.1)\n",
      "Installing collected packages: adversarial-robustness-toolbox\n",
      "  Running setup.py install for adversarial-robustness-toolbox: started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Running setup.py install for adversarial-robustness-toolbox: finished with status 'done'\n",
      "Successfully installed adversarial-robustness-toolbox-0.1\n",
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "2018-06-11 04:10:09.390226: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "--epsilon\n",
      "--data\n",
      "--networkdefinition\n",
      "--weights\n",
      "dataset:  /job/robustnesscheck-data-9b9e2782-4b17-4930-b9a4-bbe4862dc6ca/mnist.npz\n",
      "network definition:  /job/robustnesscheck-data-9b9e2782-4b17-4930-b9a4-bbe4862dc6ca/keras_original_model.json\n",
      "weights:  /job/robustnesscheck-data-9b9e2782-4b17-4930-b9a4-bbe4862dc6ca/keras_original_model.hdf5\n",
      "metrics :  {'reduction in confidence': 29.16172742843628, 'model accuracy on adversarial samples': 41.85, 'model accuracy on test data:': 97.8, 'average perturbation': 47.15782701969147}\n",
      "adversarial samples saved to :  /job/robustnesscheck-results-9b9e2782-4b17-4930-b9a4-bbe4862dc6ca/adv_samples\n",
      "Training process finished. Exit code: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Monitor the training logs\n",
    "\n",
    "if \"Model ID\" in out[1]:\n",
    "    model_id = out.fields()[1][-1]\n",
    "    !{ffdl} logs --follow {model_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above training job will create a report (`report.txt`). The file is available in COS (bucket = `robustnesscheck_result_bucket`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"model accuracy on adversarial samples\": 41.85,\n",
      "    \"model accuracy on test data:\": 97.8,\n",
      "    \"average perturbation\": 47.15782701969147,\n",
      "    \"reduction in confidence\": 29.16172742843628\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "report_file = os.path.join(model_id, \"report.txt\")\n",
    "bucket_obj = cos.Bucket(robustnesscheck_result_bucket)\n",
    "bucket_obj.download_file(report_file, \"report.txt\")\n",
    "\n",
    "with open('report.txt', \"r\") as report:\n",
    "    result = json.load(report)\n",
    "    \n",
    "print(json.dumps(result, indent=4, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the adversarial samples that were stored to COS using the below command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading robustnesscheck-results-9b9e2782-4b17-4930-b9a4-bbe4862dc6ca/training-YHWQNQSmg/adv_samples.npz ...\n",
      "Downloaded: adv_samples_from_cos.npz\n"
     ]
    }
   ],
   "source": [
    "samples_file = os.path.join(model_id, \"adv_samples.npz\")\n",
    "print('Downloading {}/{} ...'.format(robustnesscheck_result_bucket, samples_file))\n",
    "bucket_obj = cos.Bucket(robustnesscheck_result_bucket)\n",
    "bucket_obj.download_file(samples_file, \"adv_samples_from_cos.npz\")\n",
    "print('Downloaded:', \"adv_samples_from_cos.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare original with adversarial images and test model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_adv_samples = np.load(\"adv_samples_from_cos.npz\")\n",
    "x_original    = x_adv_samples[\"x_original\"]\n",
    "x_adversarial = x_adv_samples[\"x_adversarial\"]\n",
    "y             = x_adv_samples[\"y\"]\n",
    "\n",
    "x_orig = (x_original    * 255).astype('int')[:, :, :, 0]\n",
    "x_adv  = (x_adversarial * 255).astype('int')[:, :, :, 0]\n",
    "\n",
    "y_pred_orig = model.predict(x_original,    verbose=0)\n",
    "y_pred_adv  = model.predict(x_adversarial, verbose=0)\n",
    "\n",
    "fig    = plt.figure(figsize=(15, 3))\n",
    "cols   = 10\n",
    "rows   = 2\n",
    "images = list(x_orig[:cols])      + list(x_adv[:cols])\n",
    "preds  = list(y_pred_orig[:cols]) + list(y_pred_adv[:cols])\n",
    "labels = list(y[:cols])           + list(y[:cols])\n",
    "\n",
    "for i in range(0, len(images)):\n",
    "    ax = fig.add_subplot(rows, cols, i+1)\n",
    "    y_pred = np.argmax(preds[i])\n",
    "    y_orig = np.argmax(labels[i])\n",
    "    ax.set_xlabel(\"Predict: %s\" % y_pred,\n",
    "                  color = \"green\" if y_pred == y_orig else \"red\")\n",
    "    ax.tick_params(axis='both', which='both',\n",
    "                   bottom=False, top=False,\n",
    "                   right=False, left=False,\n",
    "                   labelbottom=False, labelleft=False)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Next Steps <a id=\"summary\"></a>\n",
    "\n",
    "This notebook only looked at one adversarial robustness technique (FGM). The *ART* library contains many more attacks, metrics and defenses to help you understand and improve your model's robustness. You can use this notebook as a template to experiment with all aspects of *ART*. Find more state-of-the-art methods for attacking and defending classifiers here:\n",
    "\n",
    "https://github.com/IBM/adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "Special thanks to [Anupama-Murthi](https://github.ibm.com/Anupama-Murthi) and [Vijay Arya](https://github.ibm.com/vijay-arya) who created the original notebook which we modified here to showcase how to use *ART* with *FfDL*. If you would like to try *[Watson Machine Learning (WML) Service](https://console.bluemix.net/catalog/services/machine-learning)* with *ART* check out Anupama and Vijay's notebook here:\n",
    "\n",
    "[https://github.ibm.com/robust-dlaas/ART-in-WML/Use ART to check robustness of deep learning models.ipynb](https://github.ibm.com/robust-dlaas/ART-in-WML/blob/master/Use%20ART%20to%20check%20robustness%20of%20deep%20learning%20models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright  2017, 2018 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
